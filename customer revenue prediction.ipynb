{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/ga-customer-revenue-prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load load data and normalize the json data columns\n",
    "\n",
    "gc.enable()\n",
    "  \n",
    "features = ['channelGrouping', 'date', 'fullVisitorId','socialEngagementType', 'visitId',\\\n",
    "       'visitNumber', 'visitStartTime', 'device.browser',\\\n",
    "       'device.deviceCategory', 'device.isMobile', 'device.operatingSystem', \\\n",
    "       'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\\\n",
    "       'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\\\n",
    "       'geoNetwork.subContinent', 'totals.visits', 'totals.hits',\\\n",
    "       'totals.newVisits', 'totals.pageviews', 'totals.transactionRevenue','totals.totalTransactionRevenue',\\\n",
    "       'trafficSource.adContent', 'trafficSource.campaign', 'trafficSource.medium', \\\n",
    "       'trafficSource.source', 'customDimensions']\n",
    "\n",
    "  \n",
    "        \n",
    "def load_df(csv_path):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    ans = pd.DataFrame()\n",
    "    dfs = pd.read_csv(csv_path, sep=',',\n",
    "            converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "            dtype={'fullVisitorId': 'str'}, \n",
    "            chunksize=100000)\n",
    "    \n",
    "    for df in dfs:\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        for column in JSON_COLUMNS:\n",
    "            column_as_df = json_normalize(df[column])\n",
    "            column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "            df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "\n",
    "       \n",
    "        use_df = df[features]\n",
    "        del df\n",
    "        gc.collect()\n",
    "        ans = pd.concat([ans, use_df], axis=0).reset_index(drop=True)\n",
    "   \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce memory usage by adjust the reserved size of datatypes as per need. \n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data types to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Initial Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        #else:\n",
    "            #df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and Filling Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check columns contain nulls with their null percentage\n",
    "null_percentage = pd.DataFrame()\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().sum() > 0:\n",
    "        null_percentage.loc[col,'NullPercentage'] = (df_train[col].isnull().sum())/len(df_train) * 100 \n",
    "print(null_percentage)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['totals.transactionRevenue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As this is a duplicate column\n",
    "df_train.drop('totals.totalTransactionRevenue', axis=1, inplace=True)\n",
    "df_test.drop('totals.totalTransactionRevenue', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('trafficSource.adContent', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill null in 'totals.pageviews' by mode\n",
    "print(df_train['totals.pageviews'].isnull().sum())\n",
    "print(df_train['totals.pageviews'].dtype)\n",
    "\n",
    "print(df_train['totals.pageviews'] .mode())\n",
    "print((df_train[\"totals.pageviews\"]=='1').sum())\n",
    "df_train['totals.pageviews'] = df_train['totals.pageviews'].fillna(1)\n",
    "\n",
    "df_train['totals.pageviews'] = df_train['totals.pageviews'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill null in 'totals.newVisits' by mode\n",
    "print(df_train['totals.newVisits'].isnull().sum())\n",
    "print(df_train['totals.newVisits'].dtype)\n",
    "\n",
    "print(df_train['totals.newVisits'] .mode())\n",
    "print((df_train[\"totals.newVisits\"]=='1').sum())\n",
    "df_train['totals.pageviews'] = df_train['totals.pageviews'].fillna(1)\n",
    "\n",
    "df_train['totals.pageviews'] = df_train['totals.pageviews'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_customers_no = df_train['fullVisitorId'].nunique()\n",
    "total_customers_no = df_train['visitId'].count()\n",
    "print(\"No of unique customers {} from {} total customers\".format(unique_customers_no , total_customers_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['totals.transactionRevenue'] = df_train['totals.transactionRevenue'].astype(float)\n",
    "df_train['totals.transactionRevenue'] = df_train['totals.transactionRevenue'].fillna(0)\n",
    "\n",
    "print(df_train['totals.transactionRevenue'].sort_values().unique()[1])\n",
    "print(df_train['totals.transactionRevenue'].sort_values().unique()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train.groupby('fullVisitorId')[['totals.transactionRevenue']].sum().reset_index()\n",
    "\n",
    "customers_making_revenue = (target[\"totals.transactionRevenue\"]>0).sum()\n",
    "\n",
    "print(\"No of different customers with no zero revenue= {} from total {} customers\".format(customers_making_revenue,unique_customers_no))\n",
    "print(\"Percentage of customers with no zero revenue = \",round(customers_making_revenue/unique_customers_no*100 , 2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.sort_values(by='totals.transactionRevenue' , ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=pd.cut( df_train['totals.transactionRevenue'], [-10,0,2e11]) )\n",
    "ax.set_xticklabels([\"0$ revenue customers\" , \"revenue customers\"])\n",
    "ax.set_xlabel('Revenue' , fontsize=16 , color='Black')\n",
    "ax.set_ylabel('Number of Customers' , fontsize=16 , color='Black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2['totals.transactionRevenue'] = df_train2['totals.transactionRevenue'].replace(0,np.nan)\n",
    "\n",
    "\n",
    "dev_category = df_train2.groupby('device.deviceCategory')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "dev_category.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "\n",
    "dev_os = df_train2.groupby('device.operatingSystem')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "dev_os.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "dev_os = dev_os.sort_values(by='total transactions no', ascending=False)\n",
    "\n",
    "dev_browser = df_train2.groupby('device.browser')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "dev_browser.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "dev_browser = dev_browser.sort_values(by='total transactions no', ascending=False)\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(12,4))\n",
    "fig , ax = plt.subplots(3 , 3 , figsize=(15,8))\n",
    "plt.subplot(3,3,1)\n",
    "sns.barplot(y=dev_category.index , x=dev_category['total transactions no'],palette=\"viridis\")\n",
    "plt.subplot(3,3,2)\n",
    "sns.barplot(y=dev_category.index , x=dev_category['non zero transactions no'],palette=\"viridis\").set(ylabel=None)\n",
    "plt.subplot(3,3,3)\n",
    "sns.barplot(y=dev_category.index , x=dev_category['average revenue'],palette=\"viridis\").set(ylabel=None)\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "sns.barplot(y=dev_os.index[0:6] , x=dev_os['total transactions no'].head(6) ,palette=\"viridis\")\n",
    "plt.subplot(3,3,5)\n",
    "sns.barplot(data=dev_os.head(5), y=dev_os.index[0:6], x=dev_os['non zero transactions no'].head(6), palette=\"viridis\").set(ylabel=None)\n",
    "plt.subplot(3,3,6)\n",
    "sns.barplot(data=dev_os.head(5), y=dev_os.index[0:6] , x=dev_os['average revenue'].head(6), palette=\"viridis\").set(ylabel=None)\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "sns.barplot(y=dev_browser.index[0:6] , x=dev_browser['total transactions no'].head(6) ,palette=\"viridis\")\n",
    "plt.subplot(3,3,8)\n",
    "sns.barplot(y=dev_browser.index[0:6], x=dev_os['non zero transactions no'].head(6), palette=\"viridis\").set(ylabel=None)\n",
    "plt.subplot(3,3,9)\n",
    "sns.barplot(y=dev_browser.index[0:6] , x=dev_os['average revenue'].head(6), palette=\"viridis\").set(ylabel=None)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_continent = df_train2.groupby('geoNetwork.continent')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "geo_continent.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "geo_continent = geo_continent.sort_values(by='total transactions no', ascending=False)\n",
    "\n",
    "geo_country = df_train2.groupby('geoNetwork.country')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "geo_country.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "geo_country = geo_country.sort_values(by='total transactions no', ascending=False)\n",
    "\n",
    "geo_city = df_train2.groupby('geoNetwork.city')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "geo_city.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "geo_city = geo_city.sort_values(by='total transactions no', ascending=False)\n",
    "\n",
    "geo_region = df_train2.groupby('geoNetwork.region')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "geo_region.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "geo_region = geo_region.sort_values(by='total transactions no', ascending=False)\n",
    "\n",
    "geo_network = df_train2.groupby('geoNetwork.networkDomain')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "geo_network.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "geo_network = geo_network.sort_values(by='total transactions no', ascending=False)\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(12,4))\n",
    "fig , ax = plt.subplots(5 , 3 , figsize=(15,40))\n",
    "plt.subplot(5,3,1)\n",
    "sns.barplot(y=geo_continent.index , x=geo_continent['total transactions no'],color=\"magenta\")\n",
    "plt.subplot(5,3,2)\n",
    "sns.barplot(y=geo_continent.index , x=geo_continent['non zero transactions no'],color=\"magenta\").set(ylabel=None)\n",
    "plt.subplot(5,3,3)\n",
    "sns.barplot(y=geo_continent.index , x=geo_continent['average revenue'],color=\"magenta\").set(ylabel=None)\n",
    "\n",
    "plt.subplot(5,3,4)\n",
    "sns.barplot(y=geo_country.index[0:10] , x=geo_country['total transactions no'].head(10) ,color=\"cyan\")\n",
    "plt.subplot(5,3,5)\n",
    "sns.barplot(y=geo_country.index[0:10], x=geo_country['non zero transactions no'].head(10), color=\"cyan\").set(ylabel=None)\n",
    "plt.subplot(5,3,6)\n",
    "sns.barplot(y=geo_country.index[0:10] , x=geo_country['average revenue'].head(10), color=\"cyan\").set(ylabel=None)\n",
    "\n",
    "plt.subplot(5,3,7)\n",
    "sns.barplot(y=geo_city.index[0:10] , x=geo_city['total transactions no'].head(10) ,color=\"salmon\")\n",
    "plt.subplot(5,3,8)\n",
    "sns.barplot(y=geo_city.index[0:10], x=geo_city['non zero transactions no'].head(10), color=\"salmon\").set(ylabel=None)\n",
    "plt.subplot(5,3,9)\n",
    "sns.barplot(y=geo_city.index[0:10] , x=geo_city['average revenue'].head(10), color=\"salmon\").set(ylabel=None)\n",
    "\n",
    "plt.subplot(5,3,10)\n",
    "sns.barplot(y=geo_region.index[0:10] , x=geo_region['total transactions no'].head(10) ,color=\"green\")\n",
    "plt.subplot(5,3,11)\n",
    "sns.barplot(y=geo_region.index[0:10], x=geo_region['non zero transactions no'].head(10), color=\"green\").set(ylabel=None)\n",
    "plt.subplot(5,3,12)\n",
    "sns.barplot(y=geo_region.index[0:10] , x=geo_region['average revenue'].head(10), color=\"green\").set(ylabel=None)\n",
    "\n",
    "plt.subplot(5,3,13)\n",
    "sns.barplot(y=geo_network.index[0:10] , x=geo_network['total transactions no'].head(10) ,color=\"orange\")\n",
    "plt.subplot(5,3,14)\n",
    "sns.barplot(y=geo_network.index[0:10], x=geo_network['non zero transactions no'].head(10), color=\"orange\").set(ylabel=None)\n",
    "plt.subplot(5,3,15)\n",
    "sns.barplot(y=geo_network.index[0:10] , x=geo_network['average revenue'].head(10), color=\"orange\").set(ylabel=None)\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_source = df_train2.groupby('trafficSource.source')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "tf_source.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "tf_source = tf_source.sort_values(by='total transactions no', ascending=False)\n",
    "\n",
    "tf_medium = df_train2.groupby('trafficSource.medium')[['totals.transactionRevenue']].agg(['size', 'count', 'mean'])\n",
    "tf_medium.columns = ['total transactions no','non zero transactions no','average revenue']\n",
    "tf_medium = tf_medium.sort_values(by='total transactions no', ascending=False)\n",
    "\n",
    "\n",
    "fig , ax = plt.subplots(2 , 3 , figsize=(15,10))\n",
    "plt.subplot(2,3,1)\n",
    "sns.barplot(y=tf_source.index[0:10] , x=tf_source['total transactions no'].head(10), palette=\"Spectral\")\n",
    "plt.subplot(2,3,2)\n",
    "sns.barplot(y=tf_source.index[0:10] , x=tf_source['non zero transactions no'].head(10), palette=\"Spectral\").set(ylabel=None)\n",
    "plt.subplot(2,3,3)\n",
    "sns.barplot(y=tf_source.index[0:10] , x=tf_source['average revenue'].head(10), palette=\"Spectral\").set(ylabel=None)\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "sns.barplot(y=tf_medium.index[0:10] , x=tf_medium['total transactions no'].head(10) ,palette=\"Spectral\")\n",
    "plt.subplot(2,3,5)\n",
    "sns.barplot(y=tf_medium.index[0:10], x=tf_medium['non zero transactions no'].head(10), palette=\"Spectral\").set(ylabel=None)\n",
    "plt.subplot(2,3,6)\n",
    "sns.barplot(y=tf_medium.index[0:10] , x=tf_medium['average revenue'].head(10), palette=\"Spectral\").set(ylabel=None)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # check for constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.select_dtypes(exclude='object').columns\n",
    "\n",
    "remain_features= ['visitNumber', 'device.isMobile', 'totals.pageviews','socialEngagementType','channelGrouping'\n",
    "                    ,'geoNetwork.metro','totals.visits', 'totals.hits','totals.newVisits', \n",
    "                    'trafficSource.campaign', 'customDimensions' ]\n",
    "\n",
    "for col in remain_features:\n",
    "    if len(df_train[col].unique()) == 1:\n",
    "        print(\"{} is constant\".format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['socialEngagementType'].unique())\n",
    "print(df_train['totals.visits'].unique())\n",
    "['Not Socially Engaged']\n",
    "['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that contain constant values.\n",
    "df_train.drop('socialEngagementType',axis=1, inplace=True)\n",
    "df_train.drop('totals.visits',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_train, diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['totals.hits']= df_train['totals.hits'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['totals.newVisits'].value_counts())\n",
    "print('-'*30)\n",
    "print(df_train['visitNumber'].value_counts()[:10])\n",
    "print('-'*30)\n",
    "print(df_train['device.isMobile'].value_counts()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['totals.hits'].value_counts()[:10])\n",
    "print('-'*30)\n",
    "print(df_train['totals.pageviews'].value_counts()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform & Dealing with dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['visitStartTime'][0])\n",
    "df_train['visitStartTime'] = pd.to_datetime(df_train['visitStartTime'], unit='s')\n",
    "print(df_train['visitStartTime'][0])\n",
    "df_train['vst_dayofweek'] = df_train['visitStartTime'].dt.dayofweek\n",
    "df_train['vst_hours'] = df_train['visitStartTime'].dt.hour\n",
    "df_train['vst_dayofmonth'] = df_train['visitStartTime'].dt.day\n",
    "print(df_train['vst_dayofweek'][0], df_train['vst_hours'][0], df_train['vst_dayofmonth'][0])\n",
    "df_train.drop('visitStartTime', axis = 1, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_str = '%Y%m%d'\n",
    "df_train['formated_date'] = df_train['date'].apply(lambda x: datetime.strptime(str(x), format_str))\n",
    "df_train['year'] = df_train['formated_date'].apply(lambda x:x.year)\n",
    "df_train['month'] = df_train['formated_date'].apply(lambda x:x.month)\n",
    "df_train['quarterMonth'] = df_train['formated_date'].apply(lambda x:x.day//8)\n",
    "df_train['day'] = df_train['formated_date'].apply(lambda x:x.day)\n",
    "df_train['weekday'] = df_train['formated_date'].apply(lambda x:x.weekday())\n",
    "\n",
    "df_train.drop(['date','formated_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop ID columns as they're irrelevant features\n",
    "irrelavant_features = ['fullVisitorId', 'visitId']\n",
    "for col in irrelavant_features:\n",
    "    df_train.drop(col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform categorical features to numerical using Label Encoding m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "le = LabelEncoder()\n",
    "print('Categorical columns that will be converted:')\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'O':\n",
    "        print(col)\n",
    "        #print(col, train[col].unique())\n",
    "        df_train.loc[:, col] = le.fit_transform(df_train.loc[:, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat same analysis on t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No of columns in test set ',len(df_test.columns))\n",
    "print('Columns in train and not in test are: ',set(df_train)-set(df_test))\n",
    "\n",
    "null_percentage = pd.DataFrame()\n",
    "for col in df_test.columns:\n",
    "    if df_test[col].isnull().sum() > 0:\n",
    "        null_percentage.loc[col,'NullPercentage'] = (df_test[col].isnull().sum())/len(df_test) * 100 \n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop or fill\n",
    "No of columns in test set  28\n",
    "Columns in train and not in test are:  {'vst_hours', 'weekday', 'year', 'quarterMonth', 'vst_dayofweek', 'day', 'month', 'vst_dayofmonth'}\n",
    "                           NullPercentage\n",
    "totals.newVisits                28.766724\n",
    "totals.pageviews                 0.025150\n",
    "totals.transactionRevenue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test['totals.pageviews'].isnull().sum())\n",
    "print(df_test['totals.pageviews'].dtype)\n",
    "\n",
    "print(df_test['totals.pageviews'] .mode())\n",
    "print((df_test[\"totals.pageviews\"]=='1').sum())\n",
    "\n",
    "df_test['totals.pageviews'] = df_test['totals.pageviews'].fillna(1)\n",
    "\n",
    "df_test['totals.pageviews'] = df_test['totals.pageviews'].astype(int)\n",
    "101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test['totals.newVisits'].isnull().sum())\n",
    "print(df_test['totals.newVisits'].dtype)\n",
    "\n",
    "print(df_test['totals.newVisits'] .mode())\n",
    "print((df_test[\"totals.newVisits\"]=='1').sum())\n",
    "df_test['totals.pageviews'] = df_test['totals.pageviews'].fillna(1)\n",
    "\n",
    "df_test['totals.pageviews'] = df_test['totals.pageviews'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop('totals.transactionRevenue', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_test.columns:\n",
    "    if df_test.nunique == 1:\n",
    "        print(\"{} is constant\".format(col))\n",
    "        df_test.drop(col, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['totals.hits']= df_train['totals.hits'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test['visitStartTime'][0])\n",
    "df_test['visitStartTime'] = pd.to_datetime(df_test['visitStartTime'], unit='s')\n",
    "print(df_test['visitStartTime'][0])\n",
    "df_test['vst_dayofweek'] = df_test['visitStartTime'].dt.dayofweek\n",
    "df_test['vst_hours'] = df_test['visitStartTime'].dt.hour\n",
    "df_test['vst_dayofmonth'] = df_test['visitStartTime'].dt.day\n",
    "print(df_test['vst_dayofweek'][0], df_test['vst_hours'][0], df_test['vst_dayofmonth'][0])\n",
    "df_test.drop('visitStartTime', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_str = '%Y%m%d'\n",
    "df_test['formated_date'] = df_test['date'].apply(lambda x: datetime.strptime(str(x), format_str))\n",
    "df_test['year'] = df_test['formated_date'].apply(lambda x:x.year)\n",
    "df_test['month'] = df_test['formated_date'].apply(lambda x:x.month)\n",
    "df_test['quarterMonth'] = df_test['formated_date'].apply(lambda x:x.day//8)\n",
    "df_test['day'] = df_test['formated_date'].apply(lambda x:x.day)\n",
    "df_test['weekday'] = df_test['formated_date'].apply(lambda x:x.weekday())\n",
    "\n",
    "df_test.drop(['date','formated_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelavant_features = ['fullVisitorId', 'visitId', 'socialEngagementType' , 'totals.visits']\n",
    "for col in irrelavant_features:\n",
    "    df_test.drop(col, axis ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical columns that will be converted:\n",
    "channelGrouping\n",
    "device.browser\n",
    "device.deviceCategory\n",
    "device.operatingSystem\n",
    "geoNetwork.city\n",
    "geoNetwork.continent\n",
    "geoNetwork.country\n",
    "geoNetwork.metro\n",
    "geoNetwork.networkDomain\n",
    "geoNetwork.region\n",
    "geoNetwork.subContinent\n",
    "totals.hits\n",
    "totals.newVisits\n",
    "trafficSource.adContent\n",
    "trafficSource.campaign\n",
    "trafficSource.medium\n",
    "trafficSource.source\n",
    "customDimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "print('Categorical columns that will be converted:')\n",
    "for col in df_test.columns:\n",
    "    if df_test[col].dtype == 'O':\n",
    "        print(col)\n",
    "        #print(col, train[col].unique())\n",
    "        df_test.loc[:, col] = le.fit_transform(df_test.loc[:, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Columns in train and not in test are: ',set(df_train)-set(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor(\n",
    "        num_leaves = 31,  #(default = 31) – Maximum tree leaves for base learners.\n",
    "        learning_rate = 0.03, #(default = 0.1) – Boosting learning rate. You can use callbacks parameter of fit method to shrink/adapt learning rate in training using \n",
    "                              #reset_parameter callback. Note, that this will ignore the learning_rate argument in training.\n",
    "        n_estimators = 1000, #(default = 100) – Number of boosted trees to fit.\n",
    "        subsample = .9, #(default = 1.) – Subsample ratio of the training instance.\n",
    "        colsample_bytree = .9, #(default = 1.) – Subsample ratio of columns when constructing each tree\n",
    "        random_state = 34\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train) , len(df_test))\n",
    "print(len(df_test) / len(df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train) - len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['totals.transactio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('totals.transactionRevenue' , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:1306748]\n",
    "X_val = X[1306749:]\n",
    "\n",
    "y_train = y[:1306748]\n",
    "y_val = y[1306749:]\n",
    "\n",
    "print(X_train.shape , y_train.shape)\n",
    "print(X_val.shape , y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:1306748]\n",
    "X_val = X[1306749:]\n",
    "\n",
    "y_train = y[:1306748]\n",
    "y_val = y[1306749:]\n",
    "\n",
    "print(X_train.shape , y_train.shape)\n",
    "print(X_val.shape , y_val.sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBMRegressor(colsample_bytree=0.9, learning_rate=0.03, n_estimators=1000,\n",
    "              random_state=34, subsample=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check features Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance = pd.DataFrame()\n",
    "features_importance['feature'] = X_train.columns\n",
    "features_importance['importance'] = model.booster_.feature_importance(importance_type = 'gain')\n",
    "features_importance.sort_values(by = 'importance', ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val, num_iteration = model.best_iteration_)\n",
    "predictions[predictions < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(np.log1p(y_val), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.DataFrame()\n",
    "test_predictions = model.predict(df_test[X_train.columns], num_iteration = model.best_iteration_)\n",
    "test_predictions[test_predictions < 0] = 0\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.DataFrame(test_predictions)\n",
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Ids = pd.read_csv('../input/ga-customer-revenue-prediction/test_v2.csv', usecols=['fullVisitorId'])\n",
    "test_Ids['fullVisitorId']= test_Ids['fullVisitorId'].astype(str)\n",
    "test_Ids.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test_Ids , test_predictions] , axis=1)\n",
    "submission.columns = ['fullVisitorId','PredictedLogRevenue']\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.groupby('fullVisitorId').sum().reset_index()\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
